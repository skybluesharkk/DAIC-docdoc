import os
from dotenv import load_dotenv
from pinecone import Pinecone
from pypdf import PdfReader
from langchain_upstage import UpstageDocumentParseLoader, UpstageEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_pinecone import PineconeVectorStore
from langchain.schema import Document

# 0) .env ë¡œë“œ (ì„ íƒ)
load_dotenv()

# 1) í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
UPSTAGE_API_KEY  = os.getenv("UPSTAGE_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENV     = os.getenv("PINECONE_ENV")  # ex: "asia-southeast1-gcp"
assert UPSTAGE_API_KEY and PINECONE_API_KEY and PINECONE_ENV, "í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”."

# 2) Pinecone í´ë¼ì´ì–¸íŠ¸ (ì¸ë±ìŠ¤ëŠ” ì´ë¯¸ ì¡´ì¬)
pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)
INDEX_NAME = "ngo-medical"

# 3) Upstage ì„ë² ë”© & í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì¤€ë¹„
embeddings = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model="embedding-query")
splitter   = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)

# 4) VectorStore ì´ˆê¸°í™”
vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)

# 5) ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ê¸°ë¡
PROCESSED_FILE = "processed_files.txt"
if os.path.exists(PROCESSED_FILE):
    with open(PROCESSED_FILE, "r", encoding="utf-8") as f:
        processed_files = set(line.strip() for line in f)
else:
    processed_files = set()

# ---------- ë°°ì¹˜ í¬ê¸° ì„¤ì • ----------
BATCH_SIZE = 100  # ì—…ë¡œë“œ ë°°ì¹˜ë‹¹ ìµœëŒ€ ì²­í¬ ìˆ˜

# 6) PDF íŒŒì‹± ë° ì¸ë±ì‹±
PDF_DIR = "downloaded_pdfs"
for root, _, files in os.walk(PDF_DIR):
    for fname in files:
        if not fname.lower().endswith(".pdf"):
            continue
        if fname in processed_files:
            print(f"âœ… ì´ë¯¸ ì²˜ë¦¬ë¨, ìŠ¤í‚µ: {fname}")
            continue
        pdf_path = os.path.join(root, fname)

        # 6.1) íŒŒì¼ í¬ê¸° ê²€ì¦
        if os.path.getsize(pdf_path) < 10 * 1024:
            print(f"âš ï¸ ë„ˆë¬´ ì‘ì€ íŒŒì¼, ìŠ¤í‚µ: {fname}")
            continue

        # 6.2) PDF ìœ íš¨ì„± í™•ì¸
        try:
            reader = PdfReader(pdf_path)
            if len(reader.pages) == 0:
                print(f"âš ï¸ í˜ì´ì§€ ì—†ìŒ, ìŠ¤í‚µ: {fname}")
                continue
        except Exception as e:
            print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ PDF, ìŠ¤í‚µ: {fname} ({e})")
            continue

        # 6.3) Upstage íŒŒì‹±
        print(f"â–¶ íŒŒì‹± ì¤‘: {fname}")
        loader = UpstageDocumentParseLoader(pdf_path, ocr="force")
        try:
            pages = loader.load()
        except Exception as e:
            print(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨, ìŠ¤í‚µ: {fname} ({e})")
            continue

        # 6.4) í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„±
        docs = []
        for page_idx, page in enumerate(pages):
            chunks = splitter.split_text(page.page_content)
            for chunk_idx, text in enumerate(chunks):
                docs.append(
                    Document(
                        page_content=text,
                        metadata={
                            "source_file": fname,
                            "page": page_idx,
                            "chunk": chunk_idx
                        }
                    )
                )
        if not docs:
            print(f"âš ï¸ ìƒì„±ëœ ì²­í¬ ì—†ìŒ, ìŠ¤í‚µ: {fname}")
            processed_files.add(fname)
            with open(PROCESSED_FILE, "a", encoding="utf-8") as f:
                f.write(fname + "\n")
            continue

        # 6.5) ë°°ì¹˜ë³„ ì—…ë¡œë“œ
        print(f"â³ ì¸ë±ì‹± ì¤‘ ({len(docs)} ì²­í¬): {fname}")
        for i in range(0, len(docs), BATCH_SIZE):
            batch = docs[i : i + BATCH_SIZE]
            vectorstore.add_documents(batch)
            print(f"  ğŸŒ± ë°°ì¹˜ ì—…ë¡œë“œ: {i}~{i+len(batch)}")

        # 6.6) ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
        processed_files.add(fname)
        with open(PROCESSED_FILE, "a", encoding="utf-8") as f:
            f.write(fname + "\n")
        print(f"âœ” ì²˜ë¦¬ ì™„ë£Œ: {fname}")

print("ğŸ‰ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ë° ì¸ë±ì‹± ì™„ë£Œ!")
